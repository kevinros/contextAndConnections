{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKS NOW- Normalized over mean\n",
    "#may want to take a look at other options of how to do this, but this has worked for others\n",
    "#may also want to try positional encoding\n",
    "\n",
    "class URLRet(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, num_layers, dropout):\n",
    "        super(URLRet, self).__init__()\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=dim_feedforward)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.f1 = nn.Linear(d_model, 1024)\n",
    "        self.f2 = nn.Linear(1024, 768)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim = 1)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.f1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "d_model = 768\n",
    "nhead = 4\n",
    "dim_feedforward = 2048\n",
    "num_layers=2\n",
    "dropout = .1\n",
    "\n",
    "model = URLRet(d_model, nhead, dim_feedforward, num_layers, dropout)\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "loss_fn = nn.CosineEmbeddingLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../dataloaders')\n",
    "from basic_dl import RedditDatasetFromPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = RedditDatasetFromPickle('../../data/reddit/bbc_news_scrape_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(rd[4][0].reshape(1, -1, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train(rd, model):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i in range(len(rd)):\n",
    "        (x, y) = rd[i]\n",
    "        x = x.reshape(1, -1, 768)\n",
    "        pred = model(x)\n",
    "        condition = torch.tensor(1).to('cuda:0')\n",
    "        loss = loss_fn(pred.flatten(), y, condition)\n",
    "\n",
    "        # randomly sample negative examples\n",
    "        # should really do contrastive loss over the batch\n",
    "        for i in range(5):\n",
    "            neg_idx = random.randint(0,len(rd))\n",
    "            if neg_idx == i: continue\n",
    "\n",
    "            x_neg, y_neg = rd[i]\n",
    "            x_neg = x_neg.reshape(1, -1, 768)\n",
    "\n",
    "            pred = model(x_neg)\n",
    "\n",
    "            condition = torch.tensor(0).to('cuda:0')\n",
    "            loss_neg = loss_fn(pred.flatten(), y_neg, condition)\n",
    "\n",
    "            loss += loss_neg\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    loss = train(rd, model)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(1, .1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(rd[0][0].reshape(-1, 1, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 9, 768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(rd[1][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(10, 32, 512)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
