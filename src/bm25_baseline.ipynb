{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up the pyserini sparse index\n",
    "!python3 -m pyserini.index.lucene --collection JsonCollection --input \"data_2017-09/webpages\" --index \"data_2017-09/pyserini/pyserini_index\" --generator DefaultLuceneDocumentGenerator --threads 20 -verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting BM25 parameters: k1=3.0, b=0.9\n",
      "Running data_2017-09/queries/queries_val.tsv topics, saving to out/bm25_runs/run.train.txt...\n",
      "100%|█████████████████████████████████████████| 257/257 [00:07<00:00, 33.61it/s]\n",
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-m', 'map', '-m', 'P.1', 'data_2017-09/queries/relevance_scores.txt', 'out/bm25_runs/run.train.txt']\n",
      "Results:\n",
      "map                   \tall\t0.4301\n",
      "P_1                   \tall\t0.3268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pyserini.search.lucene --index \"data_2017-09/pyserini/pyserini_index\" --topics \"data_2017-09/queries/queries_val.tsv\" --output out/bm25_runs/run.train.txt --bm25 --k1 3 --b 0.9\n",
    "\n",
    "# note MAP = MRR when there is exactly one relevant result\n",
    "# https://stats.stackexchange.com/questions/127041/mean-average-precision-vs-mean-reciprocal-rank\n",
    "!python3 -m pyserini.eval.trec_eval -m map -m P.1 \"data_2017-09/queries/relevance_scores.txt\" out/bm25_runs/run.train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-m', 'map', '-m', 'P.1', 'data_2017-09/queries/relevance_scores.txt', 'out/semantic_runs/run.train.txt']\n",
      "Results:\n",
      "map                   \tall\t0.3773\n",
      "P_1                   \tall\t0.3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pyserini.eval.trec_eval -m map -m P.1 \"data_2017-09/queries/relevance_scores.txt\" out/semantic_runs/run.train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/home/kjros2/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-m', 'map', '-m', 'P.1', 'data_2017-09/queries/relevance_scores.txt', 'out/lstm_preencoded_runs/run.val.txt']\n",
      "Results:\n",
      "map                   \tall\t0.0109\n",
      "P_1                   \tall\t0.0044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pyserini.eval.trec_eval -m map -m P.1 \"data_2017-09/queries/relevance_scores.txt\" out/lstm_preencoded_runs/run.val.txt"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
